{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBonsai(path):\n",
    "    bonsai = pd.read_csv(path)\n",
    "    bonsai = bonsai[['accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']]\n",
    "    return bonsai\n",
    "    \n",
    "def readEXLS3(path):\n",
    "    exl = pd.read_fwf(path)\n",
    "    exl.columns = exl.iloc[2]\n",
    "    exl = exl[['a_x [g]:', 'a_y [g]:', 'a_z [g]:', 'ar_x [rad/s]:', 'ar_y [rad/s]:', 'ar_z [rad/s]:']]\n",
    "    exl.rename(index=int, columns={\n",
    "        'a_x [g]:': 'accX', 'a_y [g]:': 'accY', 'a_z [g]:': 'accZ', \n",
    "        'ar_x [rad/s]:': 'gyrX', 'ar_y [rad/s]:': 'gyrY', 'ar_z [rad/s]:': 'gyrZ'\n",
    "    }, inplace=True)\n",
    "    exl = exl.iloc[3:]\n",
    "    exl.reset_index(drop=True, inplace=True)\n",
    "    exl = exl.apply(pd.to_numeric)\n",
    "    exl = exl.multiply(9.80665)\n",
    "    return exl\n",
    "\n",
    "def tagColumnNames(df, tag):\n",
    "    newColumnNames = {columnName: columnName + tag for columnName in df.columns}\n",
    "    return df.rename(index=int, columns=newColumnNames)\n",
    "\n",
    "\n",
    "fileNameLocationMap = {\n",
    "    'I-L9H': 'hip-r',\n",
    "    'I-74V': 'hip-l',\n",
    "    'I-WXB': 'knee-r',\n",
    "    'I-0GN': 'knee-l',\n",
    "    'Gait - R': 'foot-r',\n",
    "    'Gait - L': 'foot-l'\n",
    "}\n",
    "def mapFileNameToLocation(fileName):\n",
    "    for name, location in fileNameLocationMap.items():\n",
    "        if (name in fileName):\n",
    "            return location\n",
    "    return 'unknown'\n",
    "\n",
    "def loadMeasurements(path):\n",
    "    measurements = {}\n",
    "    for fileOrDir in os.listdir(path):\n",
    "        if (fileOrDir.endswith('.txt')):\n",
    "            measurement = readEXLS3(os.path.join(path, fileOrDir))\n",
    "        elif (fileOrDir.endswith('.csv')):\n",
    "            measurement = readBonsai(os.path.join(path, fileOrDir))\n",
    "        if (measurement is not None):\n",
    "            measurementLocation = mapFileNameToLocation(fileOrDir)\n",
    "            measurement = tagColumnNames(measurement, '_' + measurementLocation)\n",
    "            measurements[measurementLocation] = measurement\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroMovementWindowSize = 200 # 10ms * zeroMovement\n",
    "\n",
    "def calibrate(series):\n",
    "    zeroWindowIndex = series.abs().rolling(zeroMovementWindowSize).median().sort_values().index[0]\n",
    "    zero = series.rolling(zeroMovementWindowSize).median().iloc[zeroWindowIndex]\n",
    "    series -= zero "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize the sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfJumps = 3\n",
    "jumpBinSize = 50 # 10ms * jumpBinSize = time per bin; bundles neighbor values to avoid multiple amplitudes during same jump\n",
    "jumpSequenceLength = 800 # 10 ms * jumpSequenceLength\n",
    "relativeMaxThreshold = 7 / 12\n",
    "\n",
    "def binMeasurement(measurement, binSize):\n",
    "    absMeasurement = measurement\n",
    "    return absMeasurement.groupby(pd.cut(absMeasurement.index, np.arange(absMeasurement.index[0], absMeasurement.index[len(absMeasurement) - 1], binSize))).max()\n",
    "\n",
    "def findJumpingWindow(measurement):\n",
    "    measurement = loadMeasurements(os.path.join('..', 'data', '24-06-19', 'dennis 1'))['foot-l']['gyrY_foot-l']\n",
    "    measurement = measurement.head(int(len(measurement) / 2)) # jumping should be in first half\n",
    "    absMeasurement = measurement.abs()\n",
    "    threshold = absMeasurement.max() * relativeMaxThreshold\n",
    "    absMeasurement = absMeasurement.apply(lambda value: value if value >= threshold else 0)\n",
    "    bins = binMeasurement(absMeasurement, jumpBinSize).reset_index().drop('index', axis='columns')\n",
    "    upperBound = bins.rolling(int(jumpSequenceLength / jumpBinSize)).sum().iloc[:,0].sort_values(ascending=False).index[0]\n",
    "    lowerBound = upperBound - int(jumpSequenceLength / jumpBinSize)\n",
    "    upperBound *= jumpBinSize\n",
    "    lowerBound *= jumpBinSize\n",
    "    return lowerBound - 100, upperBound + 100\n",
    "\n",
    "def getFirstJumpIndex(measurement):\n",
    "    windowIndicies = findJumpingWindow(measurement)\n",
    "    window = measurement[windowIndicies[0]:  windowIndicies[1]]\n",
    "    threshold = window.max() * relativeMaxThreshold\n",
    "    window = window.apply(lambda value: value if value >= threshold else 0)\n",
    "    return window.loc[window > 1].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignSignals(dfX, dfY):\n",
    "    return getFirstJumpIndex(dfX) - getFirstJumpIndex(dfY)\n",
    "\n",
    "def alignAccelerationYWithRightFoot(measurements, location, axis):\n",
    "    offset = alignSignals(\n",
    "        measurements['foot-r']['accY_foot-r'], \n",
    "        measurements[location]['acc' + axis.upper() + '_' + location])\n",
    "    measurements[location] = measurements[location].shift(offset, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroMovementThreshold = 0.75 # given in meters per second\n",
    "\n",
    "def getNextBinaryBlock(series, startPosition, minSubsequentMovements, zeroMode=True):\n",
    "    start = series[startPosition:]\n",
    "    if (zeroMode):\n",
    "        start = start[series == 0]\n",
    "    else:\n",
    "        start = start[series == 1]\n",
    "    if (len(start) == 0):\n",
    "        raise ValueError\n",
    "    start = start.index[0]\n",
    "    iValue = start\n",
    "    zeroCounter = 0\n",
    "    while (iValue < len(series)):\n",
    "        if (not series[iValue]):\n",
    "            zeroCounter += 1\n",
    "            iValue += 1\n",
    "        elif (zeroCounter < minSubsequentMovements):\n",
    "            return getNextBinaryBlock(series, iValue + 1, minSubsequentMovements)\n",
    "        else:\n",
    "            break\n",
    "    return start, iValue - 1\n",
    "\n",
    "def findAllNonZeroBlocks(series, startPosition, minSubsequentZeroMovements=200, minSubsequentNonZeroMovements=29, ignoreMinSubsequentNonZeroMovements=True):\n",
    "    '''\n",
    "    Finds all blocks of movement (expects a filtered list with 1s and 0s, gives back indices of 1-blocks).\n",
    "    Thresholds:\n",
    "    - minSubsequentZeroMovements: minimal length of zero blocks to interrupt movement blocks\n",
    "    - minSubsequentNonZeroMovements: minimal length of movement blocks\n",
    "    - ignoreMinSubsequentNonZeroMovements: if minSubsequentNonZeroMovements should be ignored\n",
    "    '''\n",
    "    blocks = []\n",
    "    start = series[startPosition:][series == 1].index[0]\n",
    "    while (start < len(series)):\n",
    "        try:\n",
    "            zeroStart, zeroEnd = getNextBinaryBlock(series, start, minSubsequentZeroMovements)\n",
    "            if ((((zeroStart - 1) - start) > minSubsequentNonZeroMovements) or ignoreMinSubsequentNonZeroMovements):\n",
    "                blocks.append((start, zeroStart - 1))\n",
    "            start = zeroEnd + 1\n",
    "        except ValueError:\n",
    "            if ((((len(series) - 1) - start) > minSubsequentNonZeroMovements) or ignoreMinSubsequentNonZeroMovements):\n",
    "                blocks.append((start, len(series) - 1))\n",
    "            start = len(series)\n",
    "    return blocks\n",
    "\n",
    "def splitDataFrameIntoExercises(df, columnName):\n",
    "    measurement = df[columnName]\n",
    "    windowIndicies = findJumpingWindow(measurement)\n",
    "    filteredByTH = measurement.abs().apply(lambda value: 1 if value > zeroMovementThreshold else 0)\n",
    "    exerciseIntervals = findAllNonZeroBlocks(filteredByTH, windowIndicies[1])\n",
    "    return list(map(lambda interval: df[interval[0] : interval[1]], exerciseIntervals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restingThreshold=0.75 # given in m/s\n",
    "minRestingInterval = 25 # we are taking the resting intervals of the right foot to detect ends of strides\n",
    "minMovementInterval = 5 # movementIntervals seperate the resting intervals, we are not looking for them\n",
    "borderStrideSpacing = 10 # spacing for beginning of first and end of last stride to start and end of measurement to avoid incomplete strides\n",
    "\n",
    "def findRestingBlocks(series):\n",
    "    filteredByTH = series.abs().apply(lambda value: 1 if value < restingThreshold else 0).reset_index(drop=True)\n",
    "    return findAllNonZeroBlocks(filteredByTH, 0, minSubsequentZeroMovements=minMovementInterval, minSubsequentNonZeroMovements=minRestingInterval, ignoreMinSubsequentNonZeroMovements=False)\n",
    "\n",
    "def findFirstStride(series, nextStrides):\n",
    "    firstRestingInterval = findRestingBlocks(series)[0]\n",
    "    if (firstRestingInterval[0] > borderStrideSpacing and nextStrides[0][0] > firstRestingInterval[0]):\n",
    "        return (firstRestingInterval[0], nextStrides[0][0])\n",
    "\n",
    "def findStrideIntervals(series):\n",
    "    restingIntervals = findRestingBlocks(series)\n",
    "    strideIntervals = []\n",
    "    for i in range(len(restingIntervals) - 1):\n",
    "        if (restingIntervals[i][1] < restingIntervals[i+1][1]):\n",
    "            strideIntervals.append((restingIntervals[i][1], restingIntervals[i+1][1]))\n",
    "    if (len(series) - strideIntervals[-1][1] < borderStrideSpacing):\n",
    "        strideIntervals = strideIntervals[:-1]\n",
    "    return strideIntervals\n",
    "\n",
    "def splitExerciseIntoStrides(df):\n",
    "    measurement = df['accY_foot-r']\n",
    "    otherFoot = df['accY_foot-l']\n",
    "    strideIntervals = findStrideIntervals(measurement)\n",
    "    # in case of complete first stride being present but starting with left foot,\n",
    "    # take its start until first already measured stride\n",
    "    firstStride = findFirstStride(otherFoot, strideIntervals)\n",
    "    if (firstStride):\n",
    "        strideIntervals = [firstStride] + strideIntervals\n",
    "    splittedExercise = [df]\n",
    "    splittedExercise += list(map(lambda interval: df[interval[0] : interval[1]], strideIntervals))\n",
    "    return splittedExercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedStrideLength = 150\n",
    "\n",
    "def interpolateStride(stride):\n",
    "    difference = normalizedStrideLength - len(stride)\n",
    "    lowerHalf = math.floor(difference/2)\n",
    "    upperHalf = math.ceil(difference/2)\n",
    "    return stride.reindex(range(-lowerHalf, len(stride) + upperHalf)).fillna(0)\n",
    "    \n",
    "    \n",
    "def resampleStride(stride):\n",
    "    absStride = stride\n",
    "    return absStride.groupby(pd.cut(absStride.index, np.linspace(absStride.index[0], absStride.index[len(absStride) - 1], normalizedStrideLength + 1))).median()\n",
    "\n",
    "def normalizeStrides(strides):\n",
    "    '''\n",
    "    bring strides to same length by interpolating strides that are too short and resampling strides that are too long\n",
    "    expects a list of stride dataframes\n",
    "    '''\n",
    "    for i, stride in enumerate(strides):\n",
    "        if (len(stride) > normalizedStrideLength):\n",
    "            strides[i] = resampleStride(stride)\n",
    "        elif (len(stride) < normalizedStrideLength):\n",
    "            strides[i] = interpolateStride(stride)\n",
    "    return strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine date with calibration and sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minExerciseLength = 300 # 10ms * minExerciseLength\n",
    "expectedExerciseCount = 6\n",
    "\n",
    "def alignAll(measurements):\n",
    "    alignAccelerationYWithRightFoot(measurements, 'hip-r', 'y')\n",
    "    alignAccelerationYWithRightFoot(measurements, 'hip-l', 'y')\n",
    "    alignAccelerationYWithRightFoot(measurements, 'foot-l', 'y')\n",
    "    alignAccelerationYWithRightFoot(measurements, 'knee-l', 'y')\n",
    "    alignAccelerationYWithRightFoot(measurements, 'knee-r', 'Y')\n",
    "    \n",
    "def calibrateAll(measurements):\n",
    "    for location in measurements.values():\n",
    "        for column in location.columns:\n",
    "            calibrate(location[column])\n",
    "            \n",
    "def resetTimePointZero(mergedDf):\n",
    "    firstIndex = max([mergedDf[column].first_valid_index() for column in mergedDf])\n",
    "    lastIndex = min([mergedDf[column].last_valid_index() for column in mergedDf])\n",
    "    return mergedDf[firstIndex:lastIndex]\n",
    "        \n",
    "def loadSyncedMeasurements(path):\n",
    "    measurements = loadMeasurements(path)\n",
    "    calibrateAll(measurements)\n",
    "    alignAll(measurements)\n",
    "    mergedDf = pd.DataFrame()\n",
    "    for measurement in measurements.values():\n",
    "        mergedDf = mergedDf.join(measurement, how='outer')\n",
    "    mergedDf = resetTimePointZero(mergedDf).reset_index().drop('index', axis='columns')\n",
    "    exercisesAndTurns = splitDataFrameIntoExercises(mergedDf, 'accY_foot-r')\n",
    "    exercises = list(filter(lambda exerciseOrTurn: len(exerciseOrTurn) > minExerciseLength, exercisesAndTurns))\n",
    "    if (len(exercises) is not expectedExerciseCount):\n",
    "        print(\"Unexpected exercise count: \", len(exercises))\n",
    "    data = [mergedDf] + exercises\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledStrides = {\n",
    "    'normal': [],\n",
    "    'pelvic displacement': [],\n",
    "    'limping': [],\n",
    "    'shuffling': [],\n",
    "    'small steps': [],\n",
    "    'insecure walking': []\n",
    "}\n",
    "\n",
    "dataParentPath = os.path.join('..', 'data', '24-06-19')\n",
    "subjectPaths = [folderTuple[0] for folderTuple in os.walk(dataParentPath)][1:]\n",
    "\n",
    "for subjectPath in subjectPaths:\n",
    "    print(subjectPath)\n",
    "    loadedMeasurement = loadSyncedMeasurements(subjectPath)\n",
    "    if (len(loadedMeasurement) == expectedExerciseCount + 1):\n",
    "        for i, exercise in enumerate(loadedMeasurement[1:]):\n",
    "            strides = splitExerciseIntoStrides(exercise)[1:]\n",
    "            print(list(labelledStrides.keys())[i], len(strides))\n",
    "            labelledStrides[list(labelledStrides.keys())[i]] += normalizeStrides(strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
